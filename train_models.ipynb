{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 12:21:45.757700: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-26 12:21:49.266582: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-26 12:21:49.332517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-11-26 12:21:49.333007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:81:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-11-26 12:21:49.333091: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-26 12:21:49.341787: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-26 12:21:49.342111: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-26 12:21:49.346902: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-26 12:21:49.348723: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-26 12:21:49.350929: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-11-26 12:21:49.353497: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-11-26 12:21:49.354341: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-26 12:21:49.356498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2022-11-26 12:21:49.357647: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 12:21:49.897257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-11-26 12:21:49.897563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:81:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-11-26 12:21:49.898364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2022-11-26 12:21:49.898492: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-26 12:21:51.075436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-26 12:21:51.075594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2022-11-26 12:21:51.075607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N \n",
      "2022-11-26 12:21:51.075613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N \n",
      "2022-11-26 12:21:51.077282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10415 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
      "2022-11-26 12:21:51.078036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 6625 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:81:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from lib.methods import *\n",
    "from lib.models import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading SIPI Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIPI dataset was preprocessed using prepare_dataset notebook, so these three folders already contain Detritus/Non-Detritus images.\n",
    "\n",
    "Training: 70%\n",
    "Validation: 15%\n",
    "Testing: 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetName = '../../Detritus/Dataset-Detritus-Bubble'\n",
    "\n",
    "train_dir = DatasetName+'/train'\n",
    "validation_dir =  DatasetName+'/val'\n",
    "test_dir = DatasetName+'/test'\n",
    "\n",
    "test_all_class_dir = '../../Detritus/Dataset-Detritus-Bubble/test'\n",
    "train_all_class_dir = 'Dataset-Detritus-Bubble/train'\n",
    "val_all_class_dir = 'Dataset-Detritus-Bubble/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three datasets are loaded using keras preprocessing method *image_dataset_from_directory*. Both the batch size and the image size hyperparameters where tested using different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38391 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(train_dir,\n",
    "shuffle=True,\n",
    "batch_size=BATCH_SIZE,\n",
    "image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8226 files belonging to 2 classes.\n",
      "Found 8227 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = image_dataset_from_directory(validation_dir,\n",
    "shuffle=True,\n",
    "batch_size=BATCH_SIZE,\n",
    "image_size=IMG_SIZE)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir,\n",
    "shuffle=True,\n",
    "batch_size=BATCH_SIZE,\n",
    "image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8227 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator()\n",
    "test_data_generator = test_generator.flow_from_directory(test_all_class_dir,\n",
    "shuffle=False,\n",
    "batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamers to be used in all models\n",
    "base_learning_rate = 0.001\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "TRAINING_EPOCHS = 200\n",
    "\n",
    "\n",
    "# Callback Early Stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=20,\n",
    "                                                mode=\"min\",\n",
    "                                               restore_best_weights=True)\n",
    "\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-5, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.model_a', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks = [mcp_save, early_stopping, reduce_lr_loss]\n",
    "\n",
    "model_A = get_model_A(0.0, True, 0.0)\n",
    "history = train_model(model_A, TRAINING_EPOCHS, train_dataset, validation_dataset, base_learning_rate, callbacks)\n",
    "show_plot(history, 0.0)\n",
    "test_accuracy(model_A, test_dataset)\n",
    "print_tsne(model_A, test_dataset, 2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.model_b', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks = [mcp_save, early_stopping, reduce_lr_loss]\n",
    "\n",
    "model_B = get_model_B(0.0, True, 0.0)\n",
    "history = train_model(model_B, TRAINING_EPOCHS, train_dataset, validation_dataset, base_learning_rate, callbacks)\n",
    "show_plot(history, 0.0)\n",
    "test_accuracy(model_B, test_dataset)\n",
    "print_tsne(model_B, test_dataset, 2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobile_net(drop_value=0.0, data_aug=False, l2_reg=0.0):\n",
    "    inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "    \n",
    "    if data_aug:\n",
    "        dag = data_augmentation(inputs)\n",
    "        processed_input =  tf.keras.applications.mobilenet_v2.preprocess_input(dag)\n",
    "    else:\n",
    "        processed_input =  tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "    \n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights=None)\n",
    "    \n",
    "    x = base_model(processed_input)\n",
    "    \n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    \n",
    "    x = global_average_layer(x)\n",
    "    \n",
    "    if drop_value > 0:\n",
    "        x = keras.layers.Dropout(drop_value)(x)\n",
    "    \n",
    "    if l2_reg > 0:\n",
    "        x = keras.layers.Dense(1, kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                bias_regularizer=regularizers.l2(l2_reg),\n",
    "                activity_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    else:\n",
    "        x = keras.layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV2 Model From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, epochs:  200\n",
      "Epoch 1/200\n",
      "1200/1200 [==============================] - 138s 108ms/step - loss: 0.3954 - accuracy: 0.8165 - val_loss: 0.7067 - val_accuracy: 0.4639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmansilla/anaconda3/envs/python37/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .mobile_net_scratch/assets\n",
      "Epoch 2/200\n",
      "1200/1200 [==============================] - 112s 93ms/step - loss: 0.3480 - accuracy: 0.8399 - val_loss: 0.8139 - val_accuracy: 0.4639\n",
      "Epoch 3/200\n",
      "1200/1200 [==============================] - 116s 96ms/step - loss: 0.3062 - accuracy: 0.8594 - val_loss: 0.9185 - val_accuracy: 0.4639\n",
      "Epoch 4/200\n",
      "1200/1200 [==============================] - 123s 102ms/step - loss: 0.2660 - accuracy: 0.8831 - val_loss: 1.0047 - val_accuracy: 0.4639\n",
      "Epoch 5/200\n",
      "1200/1200 [==============================] - 120s 100ms/step - loss: 0.2418 - accuracy: 0.8959 - val_loss: 1.3634 - val_accuracy: 0.4646\n",
      "Epoch 6/200\n",
      "1200/1200 [==============================] - 114s 95ms/step - loss: 0.2198 - accuracy: 0.9076 - val_loss: 0.2290 - val_accuracy: 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmansilla/anaconda3/envs/python37/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .mobile_net_scratch/assets\n",
      "Epoch 7/200\n",
      "1200/1200 [==============================] - 115s 95ms/step - loss: 0.1966 - accuracy: 0.9191 - val_loss: 0.7249 - val_accuracy: 0.8156\n",
      "Epoch 9/200\n",
      "1200/1200 [==============================] - 119s 99ms/step - loss: 0.1886 - accuracy: 0.9225 - val_loss: 0.8826 - val_accuracy: 0.6963\n",
      "Epoch 10/200\n",
      "1200/1200 [==============================] - 119s 99ms/step - loss: 0.1819 - accuracy: 0.9255 - val_loss: 0.5250 - val_accuracy: 0.8251\n",
      "Epoch 11/200\n",
      " 237/1200 [====>.........................] - ETA: 1:33 - loss: 0.1838 - accuracy: 0.9268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 117s 97ms/step - loss: 0.1538 - accuracy: 0.9389 - val_loss: 0.1634 - val_accuracy: 0.9316\n",
      "Epoch 15/200\n",
      "1200/1200 [==============================] - 113s 94ms/step - loss: 0.1498 - accuracy: 0.9402 - val_loss: 0.1598 - val_accuracy: 0.9325\n",
      "Epoch 16/200\n",
      "1200/1200 [==============================] - 117s 97ms/step - loss: 0.1494 - accuracy: 0.9407 - val_loss: 0.1603 - val_accuracy: 0.9335\n",
      "Epoch 17/200\n",
      " 574/1200 [=============>................] - ETA: 56s - loss: 0.1495 - accuracy: 0.9387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 119s 99ms/step - loss: 0.1449 - accuracy: 0.9428 - val_loss: 0.1524 - val_accuracy: 0.9402\n",
      "Epoch 22/200\n",
      "1200/1200 [==============================] - 113s 94ms/step - loss: 0.1432 - accuracy: 0.9431 - val_loss: 0.1524 - val_accuracy: 0.9419\n",
      "Epoch 23/200\n",
      "1200/1200 [==============================] - 118s 98ms/step - loss: 0.1458 - accuracy: 0.9421 - val_loss: 0.1520 - val_accuracy: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmansilla/anaconda3/envs/python37/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .mobile_net_scratch/assets\n",
      "Epoch 24/200\n",
      " 534/1200 [============>.................] - ETA: 1:00 - loss: 0.1460 - accuracy: 0.9417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.1457 - accuracy: 0.9428 - val_loss: 0.1522 - val_accuracy: 0.9395\n",
      "Epoch 29/200\n",
      "1200/1200 [==============================] - 118s 98ms/step - loss: 0.1459 - accuracy: 0.9423 - val_loss: 0.1522 - val_accuracy: 0.9401\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 30/200\n",
      "1052/1200 [=========================>....] - ETA: 13s - loss: 0.1441 - accuracy: 0.9425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 114s 95ms/step - loss: 0.1432 - accuracy: 0.9441 - val_loss: 0.1520 - val_accuracy: 0.9406\n",
      "Epoch 33/200\n",
      "1200/1200 [==============================] - 118s 98ms/step - loss: 0.1443 - accuracy: 0.9435 - val_loss: 0.1519 - val_accuracy: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmansilla/anaconda3/envs/python37/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .mobile_net_scratch/assets\n",
      "Epoch 34/200\n",
      "1200/1200 [==============================] - 120s 100ms/step - loss: 0.1423 - accuracy: 0.9436 - val_loss: 0.1518 - val_accuracy: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmansilla/anaconda3/envs/python37/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .mobile_net_scratch/assets\n",
      "Epoch 35/200\n",
      "1200/1200 [==============================] - 117s 98ms/step - loss: 0.1409 - accuracy: 0.9443 - val_loss: 0.1518 - val_accuracy: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmansilla/anaconda3/envs/python37/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .mobile_net_scratch/assets\n",
      "Epoch 36/200\n",
      " 595/1200 [=============>................] - ETA: 58s - loss: 0.1426 - accuracy: 0.9438"
     ]
    }
   ],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mobile_net_scratch', save_best_only=True, monitor='val_loss', mode='min')\n",
    "callbacks = [mcp_save, early_stopping, reduce_lr_loss]\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "mobileNetModelSc = get_mobile_net(0.0, True, 0.0)\n",
    "history = train_model(mobileNetModelSc, TRAINING_EPOCHS, train_dataset, validation_dataset, base_learning_rate, callbacks)\n",
    "show_plot(history, 0.0)\n",
    "test_accuracy(mobileNetModelSc, test_dataset)\n",
    "print_tsne(mobileNetModelSc, test_dataset, 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.dense_net_ft', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-5, mode='min')\n",
    "callbacks = [mcp_save, early_stopping, reduce_lr_loss]\n",
    "\n",
    "def do_transfer_learning(drop_value=0.0, data_aug=False, l2_reg=0.0, input_model=None, base_model=None):\n",
    "    dense_model = input_model\n",
    "    dense_base_model = base_model\n",
    "    if (input_model is None):\n",
    "        dense_base_model = tf.keras.applications.DenseNet201(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "\n",
    "        dense_base_model.trainable = False\n",
    "\n",
    "        dense_preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "        dense_global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        dense_prediction_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "        dense_inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "        if data_aug:\n",
    "            dag = data_augmentation(dense_inputs)\n",
    "            dense_x =  tf.keras.applications.densenet.preprocess_input(dag)\n",
    "        else:\n",
    "            dense_x =  tf.keras.applications.densenet.preprocess_input(dense_inputs)\n",
    "        dense_x = dense_base_model(dense_x, training=False)\n",
    "        dense_x = dense_global_average_layer(dense_x)\n",
    "        if drop_value > 0:\n",
    "            dense_x = keras.layers.Dropout(drop_value)(dense_x)\n",
    "        dense_outputs = dense_prediction_layer(dense_x)\n",
    "        dense_model = tf.keras.Model(dense_inputs, dense_outputs)\n",
    "\n",
    "    dense_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    dense_history = dense_model.fit(train_dataset,\n",
    "                    epochs=TRAINING_EPOCHS,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks)\n",
    "    \n",
    "    acc = dense_history.history['accuracy']\n",
    "    val_acc = dense_history.history['val_accuracy']\n",
    "\n",
    "    loss = dense_history.history['loss']\n",
    "    val_loss = dense_history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title(\"Training and Validation Accuracy with Dropout {0}\".format(drop_value))\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title(\"Training and Validation Loss with Dropout {0}\".format(drop_value))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    \n",
    "    dense_base_model.trainable = True\n",
    "    \n",
    "    dense_fine_tune_at = 660\n",
    "    \n",
    "    for layer in dense_base_model.layers[:dense_fine_tune_at]:\n",
    "        layer.trainable =  False\n",
    "        \n",
    "    dense_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    total_epochs =  TRAINING_EPOCHS + TRAINING_EPOCHS\n",
    "\n",
    "    dense_history_fine = dense_model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=dense_history.epoch[-1],\n",
    "                         validation_data=validation_dataset,\n",
    "                         callbacks=callbacks)\n",
    "    \n",
    "    acc += dense_history_fine.history['accuracy']\n",
    "    val_acc += dense_history_fine.history['val_accuracy']\n",
    "\n",
    "    loss += dense_history_fine.history['loss']\n",
    "    val_loss += dense_history_fine.history['val_loss']\n",
    "    \n",
    "    loss, accuracy = dense_model.evaluate(test_dataset)\n",
    "    print('Test accuracy :', accuracy)\n",
    "    \n",
    "    \n",
    "    show_plot(acc, val_acc, loss, val_loss)\n",
    "\n",
    "    print_tsne(dense_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_net(drop_value=0.0, data_aug=False, l2_reg=0.0):\n",
    "    dense_base_model = tf.keras.applications.DenseNet201(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "\n",
    "    dense_base_model.trainable = False\n",
    "\n",
    "    dense_preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "    dense_global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    dense_prediction_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    dense_inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "    if data_aug:\n",
    "        dag = data_augmentation(dense_inputs)\n",
    "        dense_x =  tf.keras.applications.densenet.preprocess_input(dag)\n",
    "    else:\n",
    "        dense_x =  tf.keras.applications.densenet.preprocess_input(dense_inputs)\n",
    "    dense_x = dense_base_model(dense_x, training=False)\n",
    "    dense_x = dense_global_average_layer(dense_x)\n",
    "    if drop_value > 0:\n",
    "        dense_x = keras.layers.Dropout(drop_value)(dense_x)\n",
    "    dense_outputs = dense_prediction_layer(dense_x)\n",
    "    dense_model = tf.keras.Model(dense_inputs, dense_outputs)\n",
    "    return dense_base_model, dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dense_model, denseNetModel = get_dense_net(0.0, True, 0.0)\n",
    "do_transfer_learning(0.0, True, 0.0, denseNetModel, base_dense_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "def get_class_name(subdir):\n",
    "    return subdir[subdir[:subdir.rfind(\"/\")].rfind(\"/\")+1:subdir.rfind('/')]\n",
    "\n",
    "def get_file_name(subdir):\n",
    "    return subdir[subdir.rfind('/')+1:]\n",
    "\n",
    "def copy_results(files, tenancy, result):\n",
    "    for file in files:\n",
    "        class_name = get_class_name(file)\n",
    "        file_name = get_file_name(file)\n",
    "          \n",
    "        if not os.path.exists(os.path.join(os.getcwd(), final_dir)):\n",
    "            os.makedirs(os.path.join(os.getcwd(), final_dir), exist_ok=True)\n",
    "        copyfile(file, final_dir + \"/\"+file_name)\n",
    "    \n",
    "def process_results(correct_files, incorrect_files, tenancy):\n",
    "    copy_results(correct_files, tenancy, \"correct\")\n",
    "    copy_results(incorrect_files, tenancy, \"incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Resnet V2 Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.inception_resnet_v2', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-5, mode='min')\n",
    "callbacks = [mcp_save, early_stopping, reduce_lr_loss]\n",
    "\n",
    "def do_transfer_learning(drop_value=0.0, data_aug=False, l2_reg=0.0):\n",
    "    inception_resnet_base_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "    inception_resnet_base_model.trainable = False\n",
    "\n",
    "    ir_preprocess_input = tf.keras.applications.inception_resnet_v2.preprocess_input\n",
    "    ir_global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    ir_prediction_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    ir_inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "    if data_aug:\n",
    "        dag = data_augmentation(ir_inputs)\n",
    "        ir_x =  tf.keras.applications.inception_resnet_v2.preprocess_input(dag)\n",
    "    else:\n",
    "        ir_x =  tf.keras.applications.inception_resnet_v2.preprocess_input(ir_inputs)\n",
    "    ir_x = inception_resnet_base_model(ir_x, training=False)\n",
    "    ir_x = ir_global_average_layer(ir_x)\n",
    "    if drop_value > 0:\n",
    "        ir_x = keras.layers.Dropout(drop_value)(ir_x)\n",
    "    ir_outputs = ir_prediction_layer(ir_x)\n",
    "    ir_model = tf.keras.Model(ir_inputs, ir_outputs)\n",
    "    \n",
    "    ir_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    ir_history = ir_model.fit(train_dataset,\n",
    "                    epochs=TRAINING_EPOCHS,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=callbacks)\n",
    "    \n",
    "    acc = ir_history.history['accuracy']\n",
    "    val_acc = ir_history.history['val_accuracy']\n",
    "\n",
    "    loss = ir_history.history['loss']\n",
    "    val_loss = ir_history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title(\"Training and Validation Accuracy with Dropout {0}\".format(drop_value))\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title(\"Training and Validation Loss with Dropout {0}\".format(drop_value))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    \n",
    "    inception_resnet_base_model.trainable = True\n",
    "    \n",
    "    ir_fine_tune_at = 755\n",
    "    \n",
    "    for layer in inception_resnet_base_model.layers[:ir_fine_tune_at]:\n",
    "        layer.trainable =  False\n",
    "        \n",
    "    ir_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    total_epochs =  TRAINING_EPOCHS + TRAINING_EPOCHS\n",
    "\n",
    "    ir_history_fine = ir_model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=ir_history.epoch[-1],\n",
    "                         validation_data=validation_dataset,\n",
    "                         callbacks=[callback])\n",
    "    \n",
    "    acc += ir_history_fine.history['accuracy']\n",
    "    val_acc += ir_history_fine.history['val_accuracy']\n",
    "\n",
    "    loss += ir_history_fine.history['loss']\n",
    "    val_loss += ir_history_fine.history['val_loss']\n",
    "    \n",
    "    loss, accuracy = ir_model.evaluate(test_dataset)\n",
    "    print('Test accuracy :', accuracy)\n",
    "    \n",
    "    show_plot(acc, val_acc, loss, val_loss)\n",
    "    \n",
    "    print_tsne(ir_model, test_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_transfer_learning(0.0, True, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
